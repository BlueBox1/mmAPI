//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19805474
// Cuda compilation tools, release 7.5, V7.5.16
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_30
.address_size 64

	// .globl	_Z7YUV2RGBPjPfS0_S0_
.const .align 4 .u32 constAlpha;
.const .align 4 .b8 constHueColorSpaceMat[36];

.visible .func _Z7YUV2RGBPjPfS0_S0_(
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_0,
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_1,
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_2,
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_3
)
{
	.reg .f32 	%f<24>;
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [_Z7YUV2RGBPjPfS0_S0__param_0];
	ld.param.u64 	%rd2, [_Z7YUV2RGBPjPfS0_S0__param_1];
	ld.param.u64 	%rd3, [_Z7YUV2RGBPjPfS0_S0__param_2];
	ld.param.u64 	%rd4, [_Z7YUV2RGBPjPfS0_S0__param_3];
	ld.u32 	%r1, [%rd1];
	cvt.rn.f32.u32	%f1, %r1;
	ld.u32 	%r2, [%rd1+4];
	cvt.rn.f32.s32	%f2, %r2;
	add.f32 	%f3, %f2, 0fC4000000;
	ld.u32 	%r3, [%rd1+8];
	cvt.rn.f32.s32	%f4, %r3;
	add.f32 	%f5, %f4, 0fC4000000;
	ld.const.f32 	%f6, [constHueColorSpaceMat];
	ld.const.f32 	%f7, [constHueColorSpaceMat+4];
	mul.f32 	%f8, %f3, %f7;
	fma.rn.f32 	%f9, %f1, %f6, %f8;
	ld.const.f32 	%f10, [constHueColorSpaceMat+8];
	fma.rn.f32 	%f11, %f5, %f10, %f9;
	st.f32 	[%rd2], %f11;
	ld.const.f32 	%f12, [constHueColorSpaceMat+12];
	ld.const.f32 	%f13, [constHueColorSpaceMat+16];
	mul.f32 	%f14, %f3, %f13;
	fma.rn.f32 	%f15, %f1, %f12, %f14;
	ld.const.f32 	%f16, [constHueColorSpaceMat+20];
	fma.rn.f32 	%f17, %f5, %f16, %f15;
	st.f32 	[%rd3], %f17;
	ld.const.f32 	%f18, [constHueColorSpaceMat+24];
	ld.const.f32 	%f19, [constHueColorSpaceMat+28];
	mul.f32 	%f20, %f3, %f19;
	fma.rn.f32 	%f21, %f1, %f18, %f20;
	ld.const.f32 	%f22, [constHueColorSpaceMat+32];
	fma.rn.f32 	%f23, %f5, %f22, %f21;
	st.f32 	[%rd4], %f23;
	ret;
}

	// .globl	_Z13RGBAPACK_8bitfffj
.visible .func  (.param .b32 func_retval0) _Z13RGBAPACK_8bitfffj(
	.param .b32 _Z13RGBAPACK_8bitfffj_param_0,
	.param .b32 _Z13RGBAPACK_8bitfffj_param_1,
	.param .b32 _Z13RGBAPACK_8bitfffj_param_2,
	.param .b32 _Z13RGBAPACK_8bitfffj_param_3
)
{
	.reg .f32 	%f<12>;
	.reg .b32 	%r<10>;


	ld.param.f32 	%f1, [_Z13RGBAPACK_8bitfffj_param_0];
	ld.param.f32 	%f2, [_Z13RGBAPACK_8bitfffj_param_1];
	ld.param.f32 	%f3, [_Z13RGBAPACK_8bitfffj_param_2];
	ld.param.u32 	%r1, [_Z13RGBAPACK_8bitfffj_param_3];
	mov.f32 	%f4, 0f00000000;
	max.f32 	%f5, %f1, %f4;
	mov.f32 	%f6, 0f437F0000;
	min.f32 	%f7, %f5, %f6;
	max.f32 	%f8, %f2, %f4;
	min.f32 	%f9, %f8, %f6;
	max.f32 	%f10, %f3, %f4;
	min.f32 	%f11, %f10, %f6;
	cvt.rzi.u32.f32	%r2, %f11;
	cvt.rzi.u32.f32	%r3, %f9;
	shl.b32 	%r4, %r3, 8;
	cvt.rzi.u32.f32	%r5, %f7;
	shl.b32 	%r6, %r5, 16;
	or.b32  	%r7, %r2, %r1;
	or.b32  	%r8, %r7, %r4;
	or.b32  	%r9, %r8, %r6;
	st.param.b32	[func_retval0+0], %r9;
	ret;
}

	// .globl	_Z14RGBAPACK_10bitfffj
.visible .func  (.param .b32 func_retval0) _Z14RGBAPACK_10bitfffj(
	.param .b32 _Z14RGBAPACK_10bitfffj_param_0,
	.param .b32 _Z14RGBAPACK_10bitfffj_param_1,
	.param .b32 _Z14RGBAPACK_10bitfffj_param_2,
	.param .b32 _Z14RGBAPACK_10bitfffj_param_3
)
{
	.reg .f32 	%f<12>;
	.reg .b32 	%r<13>;


	ld.param.f32 	%f1, [_Z14RGBAPACK_10bitfffj_param_0];
	ld.param.f32 	%f2, [_Z14RGBAPACK_10bitfffj_param_1];
	ld.param.f32 	%f3, [_Z14RGBAPACK_10bitfffj_param_2];
	ld.param.u32 	%r1, [_Z14RGBAPACK_10bitfffj_param_3];
	mov.f32 	%f4, 0f00000000;
	max.f32 	%f5, %f1, %f4;
	mov.f32 	%f6, 0f447FC000;
	min.f32 	%f7, %f5, %f6;
	max.f32 	%f8, %f2, %f4;
	min.f32 	%f9, %f8, %f6;
	max.f32 	%f10, %f3, %f4;
	min.f32 	%f11, %f10, %f6;
	cvt.rzi.u32.f32	%r2, %f11;
	shr.u32 	%r3, %r2, 2;
	cvt.rzi.u32.f32	%r4, %f9;
	shl.b32 	%r5, %r4, 6;
	and.b32  	%r6, %r5, -256;
	cvt.rzi.u32.f32	%r7, %f7;
	shl.b32 	%r8, %r7, 14;
	and.b32  	%r9, %r8, -65536;
	or.b32  	%r10, %r3, %r1;
	or.b32  	%r11, %r10, %r6;
	or.b32  	%r12, %r11, %r9;
	st.param.b32	[func_retval0+0], %r12;
	ret;
}

	// .globl	Passthru_drvapi
.visible .entry Passthru_drvapi(
	.param .u64 Passthru_drvapi_param_0,
	.param .u64 Passthru_drvapi_param_1,
	.param .u64 Passthru_drvapi_param_2,
	.param .u64 Passthru_drvapi_param_3,
	.param .u32 Passthru_drvapi_param_4,
	.param .u32 Passthru_drvapi_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<9>;
	.reg .b32 	%r<32>;
	.reg .b64 	%rd<16>;


	ld.param.u64 	%rd1, [Passthru_drvapi_param_0];
	ld.param.u64 	%rd2, [Passthru_drvapi_param_1];
	ld.param.u64 	%rd3, [Passthru_drvapi_param_2];
	ld.param.u64 	%rd4, [Passthru_drvapi_param_3];
	ld.param.u32 	%r3, [Passthru_drvapi_param_4];
	ld.param.u32 	%r4, [Passthru_drvapi_param_5];
	mov.u32 	%r5, %ctaid.x;
	shl.b32 	%r6, %r5, 1;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	shl.b32 	%r9, %r8, 1;
	mad.lo.s32 	%r1, %r6, %r7, %r9;
	mov.u32 	%r10, %ntid.y;
	mov.u32 	%r11, %ctaid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r2, %r10, %r11, %r12;
	setp.lt.u32	%p1, %r1, %r3;
	setp.lt.u32	%p2, %r2, %r4;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB3_2;
	bra.uni 	BB3_1;

BB3_1:
	cvta.to.global.u64 	%rd5, %rd3;
	cvta.to.global.u64 	%rd6, %rd1;
	shr.u64 	%rd7, %rd4, 2;
	cvt.u32.u64	%r13, %rd7;
	cvt.u32.u64	%r14, %rd2;
	mad.lo.s32 	%r15, %r2, %r14, %r1;
	cvt.u64.u32	%rd8, %r15;
	add.s64 	%rd9, %rd6, %rd8;
	add.s32 	%r16, %r15, 1;
	cvt.u64.u32	%rd10, %r16;
	add.s64 	%rd11, %rd6, %rd10;
	ld.global.u8 	%rs1, [%rd9];
	cvt.rn.f32.u16	%f1, %rs1;
	ld.global.u8 	%rs2, [%rd11];
	cvt.rn.f32.u16	%f2, %rs2;
	mov.f32 	%f3, 0f00000000;
	max.f32 	%f4, %f1, %f3;
	mov.f32 	%f5, 0f437F0000;
	min.f32 	%f6, %f4, %f5;
	cvt.rzi.u32.f32	%r17, %f6;
	shl.b32 	%r18, %r17, 8;
	shl.b32 	%r19, %r17, 16;
	ld.const.u32 	%r20, [constAlpha];
	or.b32  	%r21, %r17, %r20;
	or.b32  	%r22, %r21, %r18;
	or.b32  	%r23, %r22, %r19;
	mad.lo.s32 	%r24, %r2, %r13, %r1;
	mul.wide.u32 	%rd12, %r24, 4;
	add.s64 	%rd13, %rd5, %rd12;
	st.global.u32 	[%rd13], %r23;
	max.f32 	%f7, %f2, %f3;
	min.f32 	%f8, %f7, %f5;
	cvt.rzi.u32.f32	%r25, %f8;
	shl.b32 	%r26, %r25, 8;
	shl.b32 	%r27, %r25, 16;
	or.b32  	%r28, %r25, %r20;
	or.b32  	%r29, %r28, %r26;
	or.b32  	%r30, %r29, %r27;
	add.s32 	%r31, %r24, 1;
	mul.wide.u32 	%rd14, %r31, 4;
	add.s64 	%rd15, %rd5, %rd14;
	st.global.u32 	[%rd15], %r30;

BB3_2:
	ret;
}

	// .globl	NV12ToARGB_drvapi
.visible .entry NV12ToARGB_drvapi(
	.param .u64 NV12ToARGB_drvapi_param_0,
	.param .u64 NV12ToARGB_drvapi_param_1,
	.param .u32 NV12ToARGB_drvapi_param_2,
	.param .u64 NV12ToARGB_drvapi_param_3,
	.param .u64 NV12ToARGB_drvapi_param_4,
	.param .u32 NV12ToARGB_drvapi_param_5,
	.param .u32 NV12ToARGB_drvapi_param_6
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<48>;
	.reg .b32 	%r<105>;
	.reg .b64 	%rd<25>;


	ld.param.u64 	%rd2, [NV12ToARGB_drvapi_param_0];
	ld.param.u64 	%rd3, [NV12ToARGB_drvapi_param_1];
	ld.param.u32 	%r20, [NV12ToARGB_drvapi_param_2];
	ld.param.u64 	%rd4, [NV12ToARGB_drvapi_param_3];
	ld.param.u64 	%rd5, [NV12ToARGB_drvapi_param_4];
	ld.param.u32 	%r22, [NV12ToARGB_drvapi_param_5];
	ld.param.u32 	%r21, [NV12ToARGB_drvapi_param_6];
	mov.u32 	%r23, %ctaid.x;
	shl.b32 	%r24, %r23, 1;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %tid.x;
	shl.b32 	%r27, %r26, 1;
	mad.lo.s32 	%r1, %r24, %r25, %r27;
	mov.u32 	%r28, %ntid.y;
	mov.u32 	%r29, %ctaid.y;
	mov.u32 	%r30, %tid.y;
	mad.lo.s32 	%r2, %r28, %r29, %r30;
	setp.lt.u32	%p1, %r1, %r22;
	setp.lt.u32	%p2, %r2, %r21;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB4_7;
	bra.uni 	BB4_1;

BB4_1:
	cvta.to.global.u64 	%rd6, %rd2;
	cvt.u32.u64	%r31, %rd3;
	mul.lo.s32 	%r32, %r2, %r31;
	add.s32 	%r33, %r20, -1;
	mad.lo.s32 	%r3, %r1, %r20, %r33;
	add.s32 	%r34, %r3, %r32;
	cvt.u64.u32	%rd7, %r34;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.u8 	%rs1, [%rd8];
	mul.wide.u16 	%r4, %rs1, 4;
	add.s32 	%r35, %r1, 1;
	mad.lo.s32 	%r5, %r35, %r20, %r33;
	add.s32 	%r36, %r5, %r32;
	cvt.u64.u32	%rd9, %r36;
	add.s64 	%rd10, %rd6, %rd9;
	ld.global.u8 	%rs2, [%rd10];
	mul.wide.u16 	%r6, %rs2, 4;
	and.b32  	%r37, %r2, 1;
	setp.eq.b32	%p4, %r37, 1;
	shr.s32 	%r7, %r2, 1;
	add.s32 	%r38, %r7, %r21;
	mul.lo.s32 	%r39, %r38, %r31;
	add.s32 	%r40, %r3, %r39;
	cvt.u64.u32	%rd11, %r40;
	add.s64 	%rd12, %rd6, %rd11;
	ld.global.u8 	%r101, [%rd12];
	add.s32 	%r41, %r5, %r39;
	cvt.u64.u32	%rd13, %r41;
	add.s64 	%rd1, %rd6, %rd13;
	@!%p4 bra 	BB4_5;
	bra.uni 	BB4_2;

BB4_2:
	ld.global.u8 	%r102, [%rd1];
	shr.u32 	%r42, %r21, 1;
	add.s32 	%r43, %r42, -1;
	setp.ge.u32	%p5, %r7, %r43;
	@%p5 bra 	BB4_4;

	add.s32 	%r44, %r21, %r7;
	add.s32 	%r45, %r44, 1;
	mul.lo.s32 	%r47, %r45, %r31;
	add.s32 	%r48, %r3, %r47;
	cvt.u64.u32	%rd14, %r48;
	add.s64 	%rd16, %rd6, %rd14;
	ld.global.u8 	%r49, [%rd16];
	add.s32 	%r50, %r101, %r49;
	add.s32 	%r51, %r50, 1;
	shr.u32 	%r101, %r51, 1;
	add.s32 	%r52, %r5, %r47;
	cvt.u64.u32	%rd17, %r52;
	add.s64 	%rd18, %rd6, %rd17;
	ld.global.u8 	%r53, [%rd18];
	add.s32 	%r54, %r102, %r53;
	add.s32 	%r55, %r54, 1;
	shr.u32 	%r102, %r55, 1;

BB4_4:
	shl.b32 	%r56, %r101, 12;
	or.b32  	%r57, %r56, %r4;
	shl.b32 	%r58, %r102, 22;
	or.b32  	%r103, %r57, %r58;
	or.b32  	%r59, %r56, %r6;
	or.b32  	%r104, %r59, %r58;
	bra.uni 	BB4_6;

BB4_5:
	shl.b32 	%r60, %r101, 12;
	or.b32  	%r61, %r60, %r4;
	ld.global.u8 	%r62, [%rd1];
	shl.b32 	%r63, %r62, 22;
	or.b32  	%r103, %r61, %r63;
	or.b32  	%r64, %r60, %r6;
	or.b32  	%r104, %r64, %r63;

BB4_6:
	shr.u64 	%rd19, %rd5, 2;
	cvt.u32.u64	%r65, %rd19;
	bfe.u32 	%r66, %r103, 10, 10;
	bfe.u32 	%r67, %r103, 20, 10;
	bfe.u32 	%r68, %r104, 10, 10;
	bfe.u32 	%r69, %r104, 20, 10;
	and.b32  	%r70, %r103, 1023;
	cvt.rn.f32.u32	%f1, %r70;
	add.s32 	%r71, %r66, -512;
	cvt.rn.f32.s32	%f2, %r71;
	add.s32 	%r72, %r67, -512;
	cvt.rn.f32.s32	%f3, %r72;
	ld.const.f32 	%f4, [constHueColorSpaceMat];
	ld.const.f32 	%f5, [constHueColorSpaceMat+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f1, %f4, %f6;
	ld.const.f32 	%f8, [constHueColorSpaceMat+8];
	fma.rn.f32 	%f9, %f3, %f8, %f7;
	ld.const.f32 	%f10, [constHueColorSpaceMat+12];
	ld.const.f32 	%f11, [constHueColorSpaceMat+16];
	mul.f32 	%f12, %f2, %f11;
	fma.rn.f32 	%f13, %f1, %f10, %f12;
	ld.const.f32 	%f14, [constHueColorSpaceMat+20];
	fma.rn.f32 	%f15, %f3, %f14, %f13;
	ld.const.f32 	%f16, [constHueColorSpaceMat+24];
	ld.const.f32 	%f17, [constHueColorSpaceMat+28];
	mul.f32 	%f18, %f2, %f17;
	fma.rn.f32 	%f19, %f1, %f16, %f18;
	ld.const.f32 	%f20, [constHueColorSpaceMat+32];
	fma.rn.f32 	%f21, %f3, %f20, %f19;
	and.b32  	%r73, %r104, 1023;
	cvt.rn.f32.u32	%f22, %r73;
	add.s32 	%r74, %r68, -512;
	cvt.rn.f32.s32	%f23, %r74;
	add.s32 	%r75, %r69, -512;
	cvt.rn.f32.s32	%f24, %r75;
	mul.f32 	%f25, %f23, %f5;
	fma.rn.f32 	%f26, %f22, %f4, %f25;
	fma.rn.f32 	%f27, %f24, %f8, %f26;
	mul.f32 	%f28, %f23, %f11;
	fma.rn.f32 	%f29, %f22, %f10, %f28;
	fma.rn.f32 	%f30, %f24, %f14, %f29;
	mul.f32 	%f31, %f23, %f17;
	fma.rn.f32 	%f32, %f22, %f16, %f31;
	fma.rn.f32 	%f33, %f24, %f20, %f32;
	mov.f32 	%f34, 0f00000000;
	max.f32 	%f35, %f9, %f34;
	mov.f32 	%f36, 0f447FC000;
	min.f32 	%f37, %f35, %f36;
	max.f32 	%f38, %f15, %f34;
	min.f32 	%f39, %f38, %f36;
	max.f32 	%f40, %f21, %f34;
	min.f32 	%f41, %f40, %f36;
	cvt.rzi.u32.f32	%r76, %f41;
	shr.u32 	%r77, %r76, 2;
	cvt.rzi.u32.f32	%r78, %f39;
	shl.b32 	%r79, %r78, 6;
	and.b32  	%r80, %r79, -256;
	cvt.rzi.u32.f32	%r81, %f37;
	shl.b32 	%r82, %r81, 14;
	and.b32  	%r83, %r82, -65536;
	ld.const.u32 	%r84, [constAlpha];
	or.b32  	%r85, %r77, %r84;
	or.b32  	%r86, %r85, %r80;
	or.b32  	%r87, %r86, %r83;
	mad.lo.s32 	%r88, %r2, %r65, %r1;
	cvta.to.global.u64 	%rd20, %rd4;
	mul.wide.u32 	%rd21, %r88, 4;
	add.s64 	%rd22, %rd20, %rd21;
	st.global.u32 	[%rd22], %r87;
	max.f32 	%f42, %f27, %f34;
	min.f32 	%f43, %f42, %f36;
	max.f32 	%f44, %f30, %f34;
	min.f32 	%f45, %f44, %f36;
	max.f32 	%f46, %f33, %f34;
	min.f32 	%f47, %f46, %f36;
	cvt.rzi.u32.f32	%r89, %f47;
	shr.u32 	%r90, %r89, 2;
	cvt.rzi.u32.f32	%r91, %f45;
	shl.b32 	%r92, %r91, 6;
	and.b32  	%r93, %r92, -256;
	cvt.rzi.u32.f32	%r94, %f43;
	shl.b32 	%r95, %r94, 14;
	and.b32  	%r96, %r95, -65536;
	or.b32  	%r97, %r90, %r84;
	or.b32  	%r98, %r97, %r93;
	or.b32  	%r99, %r98, %r96;
	add.s32 	%r100, %r88, 1;
	mul.wide.u32 	%rd23, %r100, 4;
	add.s64 	%rd24, %rd20, %rd23;
	st.global.u32 	[%rd24], %r99;

BB4_7:
	ret;
}


